library 
```{r}
library(readtext) #Needed for readtext
library(tidyverse)
library(tm) #clean
library(tidytext) #unnest
library(textstem) #lemmatize
```

BY AUTHOR POSITIONALITY
```{r}
#white male 
#read
wm_df <- readtext("data/white_male_auth", cache=FALSE)
#remove .txt
wm_df$doc_id<-gsub(".txt", "", paste(wm_df$doc_id))
#still nested for +-10
wm_nest <- wm_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "white male") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
wm_unnest <- wm_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
wm <- anti_join(wm_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
wm <- wm %>% mutate(word = removePunctuation(word))
#lemmatization
wm_lem <- wm$word %>% lemmatize_words()
wm_lem <- as.data.frame(wm_lem) 
wm_lem <- wm_lem %>%
  mutate(id = row_number()) 
wm_lem_count <- wm %>% mutate(id = row_number())
wm <- full_join(wm_lem, wm_lem_count, by = c("id" = "id"))
wm <- wm %>% select(-id) %>% rename(lem = "wm_lem")

#white female 
#read
wf_df <- readtext("data/white_fem_auth", cache=FALSE)
#remove .txt
wf_df$doc_id<-gsub(".txt", "", paste(wf_df$doc_id))
#still nested for +-10
wf_nest <- wf_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "white fem") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
wf_unnest <- wf_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words
wf <- anti_join(wf_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
wf <- wf %>% mutate(word = removePunctuation(word))
#lemmatization
wf_lem <- wf$word %>% lemmatize_words()
wf_lem <- as.data.frame(wf_lem) 
wf_lem <- wf_lem %>%
  mutate(id = row_number()) 
wf_lem_count <- wf %>% mutate(id = row_number())
wf <- full_join(wf_lem, wf_lem_count, by = c("id" = "id"))
wf <- wf %>% select(-id) %>% rename(lem = "wf_lem")

#black female 
#read
bf_df <- readtext("data/black_fem_auth", cache=FALSE)
#remove .txt
bf_df$doc_id<-gsub(".txt", "", paste(bf_df$doc_id))
#still nested for +-10
bf_nest <- bf_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "black fem") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
bf_unnest <- bf_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words
bf <- anti_join(bf_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
bf <- bf %>% mutate(word = removePunctuation(word))
#lemmatization
bf_lem <- bf$word %>% lemmatize_words()
bf_lem <- as.data.frame(bf_lem) 
bf_lem <- bf_lem %>%
  mutate(id = row_number()) 
bf_lem_count <- bf %>% mutate(id = row_number())
bf <- full_join(bf_lem, bf_lem_count, by = c("id" = "id"))
bf <- bf %>% select(-id) %>% rename(lem = "bf_lem")

#remove unneeded
rm(wm_df, wm_lem_count, wf_df, wf_lem_count, bf_df, bf_lem_count, wm_nest, wf_nest, bf_nest)


write.csv(wm_unnest, "data/wm_unnest_auth")
write.csv(wf_unnest, "data/wf_unnest_auth")
write.csv(bf_unnest, "data/bf_unnest_auth")
write.csv(wm, "data/wm_auth")
write.csv(wf, "data/wf_auth")
write.csv(bf, "data/bf_auth")
```

BY PROTAG POSITIONALITY
```{r}
#white male 
#read
wm_df <- readtext("data/white_male_char", cache=FALSE)
#remove .txt
wm_df$doc_id<-gsub(".txt", "", paste(wm_df$doc_id))
#still nested for +-10
wm_nest <- wm_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "white male") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
wm_unnest <- wm_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
wm <- anti_join(wm_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
wm <- wm %>% mutate(word = removePunctuation(word))
#lemmatization
wm_lem <- wm$word %>% lemmatize_words()
wm_lem <- as.data.frame(wm_lem) 
wm_lem <- wm_lem %>%
  mutate(id = row_number()) 
wm_lem_count <- wm %>% mutate(id = row_number())
wm <- full_join(wm_lem, wm_lem_count, by = c("id" = "id"))
wm <- wm %>% select(-id) %>% rename(lem = "wm_lem")

#white female 
#read
wf_df <- readtext("data/white_fem_char", cache=FALSE)
#remove .txt
wf_df$doc_id<-gsub(".txt", "", paste(wf_df$doc_id))
#still nested for +-10
wf_nest <- wf_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "white fem") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
wf_unnest <- wf_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words
wf <- anti_join(wf_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
wf <- wf %>% mutate(word = removePunctuation(word))
#lemmatization
wf_lem <- wf$word %>% lemmatize_words()
wf_lem <- as.data.frame(wf_lem) 
wf_lem <- wf_lem %>%
  mutate(id = row_number()) 
wf_lem_count <- wf %>% mutate(id = row_number())
wf <- full_join(wf_lem, wf_lem_count, by = c("id" = "id"))
wf <- wf %>% select(-id) %>% rename(lem = "wf_lem")

#black female 
#read
bf_df <- readtext("data/black_fem_char", cache=FALSE)
#remove .txt
bf_df$doc_id<-gsub(".txt", "", paste(bf_df$doc_id))
#still nested for +-10
bf_nest <- bf_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "black fem") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
bf_unnest <- bf_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words
bf <- anti_join(bf_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
bf <- bf %>% mutate(word = removePunctuation(word))
#lemmatization
bf_lem <- bf$word %>% lemmatize_words()
bf_lem <- as.data.frame(bf_lem) 
bf_lem <- bf_lem %>%
  mutate(id = row_number()) 
bf_lem_count <- bf %>% mutate(id = row_number())
bf <- full_join(bf_lem, bf_lem_count, by = c("id" = "id"))
bf <- bf %>% select(-id) %>% rename(lem = "bf_lem")

#remove unneeded
rm(wm_df, wm_lem_count, wf_df, wf_lem_count, bf_df, bf_lem_count, wm_nest, wf_nest, bf_nest)


write.csv(wm_unnest, "data/wm_unnest_char")
write.csv(wf_unnest, "data/wf_unnest_char")
write.csv(bf_unnest, "data/bf_unnest_char")
write.csv(wm, "data/wm_char")
write.csv(wf, "data/wf_char")
write.csv(bf, "data/bf_char")
```

BY GENDER PROTOG
```{r}
#male 
#read
wm <- readtext("data/white_male_char", cache=FALSE)
bm <- readtext("data/black_male_char", cache=FALSE)
male <- bind_rows(wm, bm)
#remove .txt
male$doc_id<-gsub(".txt", "", paste(male$doc_id))
#still nested for +-10
male_nest <- male %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "male") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
male_unnest <- male_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
male <- anti_join(male_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
male <- male %>% mutate(word = removePunctuation(word))
#lemmatization
male_lem <- male$word %>% lemmatize_words()
male_lem <- as.data.frame(male_lem) 
male_lem <- male_lem %>%
  mutate(id = row_number()) 
male_lem_count <- male %>% mutate(id = row_number())
male <- full_join(male_lem, male_lem_count, by = c("id" = "id"))
male_char_gender <- male %>% select(-id) %>% rename(lem = "male_lem")

#female 
wf <- readtext("data/white_fem_char", cache=FALSE)
bf <- readtext("data/black_fem_char", cache=FALSE)
fem <- bind_rows(wf, bf)
#remove .txt
fem$doc_id<-gsub(".txt", "", paste(fem$doc_id))
#still nested for +-10
fem_nest <- fem %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "female") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
fem_unnest <- fem_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
fem <- anti_join(fem_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
fem <- fem %>% mutate(word = removePunctuation(word))
#lemmatization
fem_lem <- fem$word %>% lemmatize_words()
fem_lem <- as.data.frame(fem_lem) 
fem_lem <- fem_lem %>%
  mutate(id = row_number()) 
fem_lem_count <- fem %>% mutate(id = row_number())
fem <- full_join(fem_lem, fem_lem_count, by = c("id" = "id"))
fem_char_gender <- fem %>% select(-id) %>% rename(lem = "fem_lem")

#remove unneeded
rm(wm, male_lem_count, wf, fem_lem_count, bf, bm, male_nest, fem_nest)


write.csv(fem_unnest, "data/fem_unnest_char_gender")
write.csv(male_unnest, "data/male_unnest_char_gender")
write.csv(fem_char_gender, "data/fem_char_gender")
write.csv(male_char_gender, "data/male_char_gender")
```

BY GENDER AUTH
```{r}
#male 
#read
wm <- readtext("data/white_male_auth", cache=FALSE)
bm <- readtext("data/black_male_auth", cache=FALSE)
male <- bind_rows(wm, bm)
#remove .txt
male$doc_id<-gsub(".txt", "", paste(male$doc_id))
#still nested for +-10
male_nest <- male %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "male") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
male_unnest <- male_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
male <- anti_join(male_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
male <- male %>% mutate(word = removePunctuation(word))
#lemmatization
male_lem <- male$word %>% lemmatize_words()
male_lem <- as.data.frame(male_lem) 
male_lem <- male_lem %>%
  mutate(id = row_number()) 
male_lem_count <- male %>% mutate(id = row_number())
male <- full_join(male_lem, male_lem_count, by = c("id" = "id"))
male_auth_gender <- male %>% select(-id) %>% rename(lem = "male_lem")

#female 
wf <- readtext("data/white_fem_auth", cache=FALSE)
bf <- readtext("data/black_fem_auth", cache=FALSE)
fem <- bind_rows(wf, bf)
#remove .txt
fem$doc_id<-gsub(".txt", "", paste(fem$doc_id))
#still nested for +-10
fem_nest <- fem %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "female") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
fem_unnest <- fem_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
fem <- anti_join(fem_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
fem <- fem %>% mutate(word = removePunctuation(word))
#lemmatization
fem_lem <- fem$word %>% lemmatize_words()
fem_lem <- as.data.frame(fem_lem) 
fem_lem <- fem_lem %>%
  mutate(id = row_number()) 
fem_lem_count <- fem %>% mutate(id = row_number())
fem <- full_join(fem_lem, fem_lem_count, by = c("id" = "id"))
fem_auth_gender <- fem %>% select(-id) %>% rename(lem = "fem_lem")

#remove unneeded
rm(wm, male_lem_count, wf, fem_lem_count, bf, bm, fem_nest, male_nest)


write.csv(fem_unnest, "data/fem_unnest_auth_gender")
write.csv(male_unnest, "data/male_unnest_auth_gender")
write.csv(fem_auth_gender, "data/fem_auth_gender")
write.csv(male_auth_gender, "data/male_auth_gender")
```

RACE
```{r}
#white 
#read
w_df <- readtext("data/white", cache=FALSE)
#remove .txt
w_df$doc_id<-gsub(".txt", "", paste(w_df$doc_id))
#still nested for +-10
w_nest <- w_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "white") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
w_unnest <- w_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words and punctuation
w <- anti_join(w_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
w <- w %>% mutate(word = removePunctuation(word))
#lemmatization
w_lem <- w$word %>% lemmatize_words()
w_lem <- as.data.frame(w_lem) 
w_lem <- w_lem %>%
  mutate(id = row_number()) 
w_lem_count <- w %>% mutate(id = row_number())
w <- full_join(w_lem, w_lem_count, by = c("id" = "id"))
w <- w %>% select(-id) %>% rename(lem = "w_lem")

#black  
#read
b_df <- readtext("data/black", cache=FALSE)
#remove .txt
b_df$doc_id<-gsub(".txt", "", paste(b_df$doc_id))
#still nested for +-10
b_nest <- b_df %>%
  mutate(text = str_to_lower(text)) %>% 
  mutate(positionality = "black") %>%
  mutate(text = str_squish(text)) %>%
  mutate(text = removeNumbers(text))
#unnest
b_unnest <- b_nest %>% 
  unnest_tokens(output = "word", input = "text")
#remove stop words
b <- anti_join(b_unnest, stop_words, by = c("word" = "word"), .keep_all = true)
b <- b %>% mutate(word = removePunctuation(word))
#lemmatization
b_lem <- b$word %>% lemmatize_words()
b_lem <- as.data.frame(b_lem) 
b_lem <- b_lem %>%
  mutate(id = row_number()) 
b_lem_count <- b %>% mutate(id = row_number())
b <- full_join(b_lem, b_lem_count, by = c("id" = "id"))
b <- b %>% select(-id) %>% rename(lem = "b_lem")

#remove unneeded
rm(w_df, w_lem_count, b_df, b_lem_count, b_nest, w_nest)


write.csv(w_unnest, "data/w_unnest")
write.csv(b_unnest, "data/b_unnest")
write.csv(w, "data/w")
write.csv(b, "data/b")
```



DFs
```{r}
#all novels
all_novels_auth <- bind_rows(wm_auth, wf_auth, bf_auth) %>%
  group_by(doc_id) %>%
  mutate(id = row_number()) %>%
  mutate(tot_words = n()) %>%
  ungroup() 

all_novels_auth_gender <- bind_rows(fem_auth_gender, male_auth_gender) %>%
  group_by(doc_id) %>%
  mutate(id = row_number()) %>%
  mutate(tot_words = n()) %>%
  ungroup() 


all_novels_race <- bind_rows(w, b) %>%
  group_by(doc_id) %>%
  mutate(id = row_number()) %>%
  mutate(tot_words = n()) %>%
  ungroup() 


all_novels_char <- bind_rows(wm_char, wf_char, bf_char) %>%
  group_by(doc_id) %>%
  mutate(id = row_number()) %>%
  mutate(tot_words = n()) %>%
  ungroup() 

all_novels_char_gender <- bind_rows(fem_char_gender, male_char_gender) %>%
  group_by(doc_id) %>%
  mutate(id = row_number()) %>%
  mutate(tot_words = n()) %>%
  ungroup() 

#VISUALIZATIONS !!!

#Most common words used


#Sentiment score per novel
auth_afinn <-
    all_novels_auth %>% 
   inner_join(get_sentiments("afinn")) %>% 
   group_by(doc_id, positionality, tot_words) %>% 
   summarise(sentiment = sum(value)) %>% 
  mutate(perc = sentiment/tot_words) %>%
   mutate(method = "AFINN") %>%
  mutate(positionality_choice = "Gender and Race")


race_afinn <- 
    all_novels_race %>% 
   inner_join(get_sentiments("afinn")) %>% 
   group_by(doc_id, positionality, tot_words) %>% 
   summarise(sentiment = sum(value)) %>% 
  mutate(perc = sentiment/tot_words) %>%
   mutate(method = "AFINN") %>%
  mutate(positionality_choice = "Race")


auth_gender_afinn <-
  all_novels_auth_gender %>% 
   inner_join(get_sentiments("afinn")) %>% 
   group_by(doc_id, positionality, tot_words) %>% 
   summarise(sentiment = sum(value)) %>% 
  mutate(perc = sentiment/tot_words) %>%
   mutate(method = "AFINN") %>%
  mutate(positionality_choice = "Gender")


   #bing and nrc
bing_and_nrc_auth <- 
  bind_rows(
  all_novels_auth %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  all_novels_auth %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative")) 
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, doc_id, sentiment, positionality, tot_words) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(perc = sentiment / tot_words)%>%
  mutate(positionality_choice = "Gender and Race")

bing_and_nrc_race <-
                bind_rows(
  all_novels_race %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  all_novels_race %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, doc_id, sentiment, positionality, tot_words) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(perc = sentiment / tot_words) %>%
  mutate(positionality_choice = "Race") 


bing_and_nrc_auth_gender <-
                bind_rows(
  all_novels_auth_gender %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  all_novels_auth_gender %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, doc_id, sentiment, positionality, tot_words) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(perc = sentiment / tot_words) %>%
  mutate(positionality_choice = "Gender")

afinn_auth <- bind_rows(auth_afinn, race_afinn, auth_gender_afinn) 

bing_and_nrc_auth <- bind_rows(bing_and_nrc_auth, bing_and_nrc_race, bing_and_nrc_auth_gender) 

sent_per_auth <- bind_rows(afinn_auth, bing_and_nrc_auth) %>%
  mutate(choice = "auth")


#-----#
  
char_afinn <-
    all_novels_char %>% 
   inner_join(get_sentiments("afinn")) %>% 
   group_by(doc_id, positionality, tot_words) %>% 
   summarise(sentiment = sum(value)) %>% 
  mutate(perc = sentiment/tot_words) %>%
   mutate(method = "AFINN") %>%
  mutate(positionality_choice = "Gender and Race")


char_gender_afinn <-
  all_novels_auth_gender %>% 
   inner_join(get_sentiments("afinn")) %>% 
   group_by(doc_id, positionality, tot_words) %>% 
   summarise(sentiment = sum(value)) %>% 
  mutate(perc = sentiment/tot_words) %>%
   mutate(method = "AFINN") %>%
  mutate(positionality_choice = "Gender")


   #bing and nrc
bing_and_nrc_char <- 
  bind_rows(
  all_novels_auth %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  all_novels_auth %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative")) 
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, doc_id, sentiment, positionality, tot_words) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(perc = sentiment / tot_words)%>%
  mutate(positionality_choice = "Gender and Race")



bing_and_nrc_char_gender <-
                bind_rows(
  all_novels_auth_gender %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  all_novels_auth_gender %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, doc_id, sentiment, positionality, tot_words) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(perc = sentiment / tot_words) %>%
  mutate(positionality_choice = "Gender")

afinn_char <- bind_rows(char_afinn, race_afinn, char_gender_afinn) 

bing_and_nrc_char <- bind_rows(bing_and_nrc_char, bing_and_nrc_race, bing_and_nrc_char_gender) 

sent_per_char <- bind_rows(afinn_char, bing_and_nrc_char) %>%
  mutate(choice = "char")

sent_per <- bind_rows(sent_per_auth, sent_per_char)

write.csv(sent_per, "data/sent_per")

#NRC emotion percentages


#Most common mental health words


#Frequency of mental health terms in novel


#Ratio of derogatory to non-derogatory words


#Sentiment +-10 words around mental health words 
```

